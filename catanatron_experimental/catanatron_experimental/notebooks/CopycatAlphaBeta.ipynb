{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8efa3f-d4f6-42ba-8487-30f1ae3bc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e \"git+https://github.com/bcollazo/catanatron.git@master#egg=catanatron&subdirectory=catanatron_core\"\n",
    "!pip install -e \"git+https://github.com/bcollazo/catanatron.git@master#egg=catanatron_gym&subdirectory=catanatron_gym\"\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install -e \"git+https://github.com/bcollazo/catanatron.git@master#egg=catanatron_experimental&subdirectory=catanatron_experimental\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78929160-6ea7-45ed-b9e3-fa9f5c37f6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 10:56:32.729748: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-15 10:56:32.729783: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "from catanatron_gym.envs.catanatron_env import ACTION_SPACE_SIZE\n",
    "from catanatron_gym.features import get_feature_ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981519ce-ea17-42c7-93f1-099bbe653452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datasets exists\n",
    "import pathlib\n",
    "import urllib.request\n",
    "\n",
    "DATA_FOLDER = \"./data\"\n",
    "DATASET_PATH = pathlib.Path(DATA_FOLDER, \"1v1-ab2s-nodiscard\", \"main.csv.gzip\")\n",
    "VALIDATION_DATASET_PATH = pathlib.Path(DATA_FOLDER, \"1v1-ab2s-nodiscard-validation\", \"main.csv.gzip\")\n",
    "\n",
    "DATASET_PATH.parents[0].mkdir(parents=True, exist_ok=True)\n",
    "VALIDATION_DATASET_PATH.parents[0].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATASET_PATH.exists():\n",
    "    urllib.request.urlretrieve(\"https://catanatron-public.s3.us-east-2.amazonaws.com/1v1-ab2s-nodiscard/main.csv.gzip\", DATASET_PATH)\n",
    "if not VALIDATION_DATASET_PATH.exists():\n",
    "    urllib.request.urlretrieve(\"https://catanatron-public.s3.us-east-2.amazonaws.com/1v1-ab2s-nodiscard-validation/main.csv.gzip\", VALIDATION_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390f0d35-6f6b-488f-a396-592e5227d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004976\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "SHUFFLE_SEED = 1\n",
    "\n",
    "rows_per_bytes = 6345 / 1209734  # ~0.0052\n",
    "size = os.path.getsize(DATASET_PATH)  # bytes\n",
    "estimated_rows = int(size * rows_per_bytes)\n",
    "print(estimated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f0fabd-87c6-42c6-9cc8-2c0c9522a5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_BANK_BRICK</th>\n",
       "      <th>F_BANK_DEV_CARDS</th>\n",
       "      <th>F_BANK_ORE</th>\n",
       "      <th>F_BANK_SHEEP</th>\n",
       "      <th>F_BANK_WHEAT</th>\n",
       "      <th>F_BANK_WOOD</th>\n",
       "      <th>F_EDGE(0, 1)_P0_ROAD</th>\n",
       "      <th>F_EDGE(0, 1)_P1_ROAD</th>\n",
       "      <th>F_EDGE(0, 20)_P0_ROAD</th>\n",
       "      <th>F_EDGE(0, 20)_P1_ROAD</th>\n",
       "      <th>...</th>\n",
       "      <th>BT_3692</th>\n",
       "      <th>BT_3693</th>\n",
       "      <th>BT_3694</th>\n",
       "      <th>BT_3695</th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RETURN</th>\n",
       "      <th>DISCOUNTED_RETURN</th>\n",
       "      <th>TOURNAMENT_RETURN</th>\n",
       "      <th>DISCOUNTED_TOURNAMENT_RETURN</th>\n",
       "      <th>VICTORY_POINTS_RETURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.185433</td>\n",
       "      <td>5.962317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 4316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   F_BANK_BRICK  F_BANK_DEV_CARDS  F_BANK_ORE  F_BANK_SHEEP  F_BANK_WHEAT  \\\n",
       "0          19.0              25.0        19.0          19.0          19.0   \n",
       "1          19.0              25.0        19.0          19.0          19.0   \n",
       "2          18.0              25.0        19.0          18.0          17.0   \n",
       "3          18.0              25.0        19.0          18.0          17.0   \n",
       "4          17.0              25.0        19.0          18.0          17.0   \n",
       "5          17.0              25.0        19.0          18.0          17.0   \n",
       "6          18.0              25.0        19.0          18.0          17.0   \n",
       "7          19.0              25.0        19.0          18.0          17.0   \n",
       "8          19.0              25.0        19.0          18.0          17.0   \n",
       "9          19.0              25.0        18.0          17.0          17.0   \n",
       "\n",
       "   F_BANK_WOOD  F_EDGE(0, 1)_P0_ROAD  F_EDGE(0, 1)_P1_ROAD  \\\n",
       "0         19.0                   0.0                   0.0   \n",
       "1         19.0                   0.0                   0.0   \n",
       "2         17.0                   0.0                   0.0   \n",
       "3         17.0                   0.0                   0.0   \n",
       "4         17.0                   0.0                   0.0   \n",
       "5         17.0                   0.0                   0.0   \n",
       "6         17.0                   0.0                   0.0   \n",
       "7         18.0                   0.0                   0.0   \n",
       "8         18.0                   0.0                   0.0   \n",
       "9         18.0                   0.0                   0.0   \n",
       "\n",
       "   F_EDGE(0, 20)_P0_ROAD  F_EDGE(0, 20)_P1_ROAD  ...  BT_3692  BT_3693  \\\n",
       "0                    0.0                    0.0  ...      0.0      0.0   \n",
       "1                    0.0                    0.0  ...      0.0      0.0   \n",
       "2                    0.0                    0.0  ...      0.0      0.0   \n",
       "3                    0.0                    0.0  ...      0.0      0.0   \n",
       "4                    0.0                    0.0  ...      0.0      0.0   \n",
       "5                    0.0                    0.0  ...      0.0      0.0   \n",
       "6                    0.0                    0.0  ...      0.0      0.0   \n",
       "7                    0.0                    0.0  ...      0.0      0.0   \n",
       "8                    0.0                    0.0  ...      0.0      0.0   \n",
       "9                    0.0                    0.0  ...      0.0      0.0   \n",
       "\n",
       "   BT_3694  BT_3695  ACTION  RETURN  DISCOUNTED_RETURN  TOURNAMENT_RETURN  \\\n",
       "0      0.0      0.0     110     0.0                0.0                6.0   \n",
       "1      0.0      0.0      52     0.0                0.0                6.0   \n",
       "2      0.0      0.0     107     0.0                0.0                6.0   \n",
       "3      0.0      0.0      45     0.0                0.0                6.0   \n",
       "4      0.0      0.0       0     0.0                0.0                6.0   \n",
       "5      0.0      0.0     289     0.0                0.0                6.0   \n",
       "6      0.0      0.0       0     0.0                0.0                6.0   \n",
       "7      0.0      0.0      50     0.0                0.0                6.0   \n",
       "8      0.0      0.0     289     0.0                0.0                6.0   \n",
       "9      0.0      0.0       0     0.0                0.0                6.0   \n",
       "\n",
       "   DISCOUNTED_TOURNAMENT_RETURN  VICTORY_POINTS_RETURN  \n",
       "0                      3.185433               5.962317  \n",
       "1                      3.185433               5.962317  \n",
       "2                      3.185433               5.962317  \n",
       "3                      3.185433               5.962317  \n",
       "4                      3.185433               5.962317  \n",
       "5                      3.185433               5.962317  \n",
       "6                      3.185433               5.962317  \n",
       "7                      3.185433               5.962317  \n",
       "8                      3.185433               5.962317  \n",
       "9                      3.185433               5.962317  \n",
       "\n",
       "[10 rows x 4316 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATASET_PATH, nrows=10, compression='gzip')\n",
    "validation_data = pd.read_csv(VALIDATION_DATASET_PATH, nrows=10, compression='gzip')\n",
    "\n",
    "assert (data.columns == validation_data.columns).all()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1c3ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 10:56:35.795027: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-15 10:56:35.821854: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-15 10:56:35.821879: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bcollazo-Erazer-X510): /proc/driver/nvidia/version does not exist\n",
      "2022-01-15 10:56:35.822543: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# ===== Read Dataset\n",
    "INPUT_COLUMNS = list(filter(lambda x: x.startswith(\"F_\"), data.columns))\n",
    "# INPUT_COLUMNS = list(filter(lambda x: x.startswith(\"BT_\"), data.columns))\n",
    "LABEL_COLUMN = \"ACTION\"\n",
    "INPUT_SHAPE = (len(INPUT_COLUMNS),)\n",
    "\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    str(DATASET_PATH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=1,\n",
    "    label_name=LABEL_COLUMN,\n",
    "    select_columns=INPUT_COLUMNS + [LABEL_COLUMN],\n",
    "    compression_type=\"GZIP\",\n",
    "    shuffle=True,  # shuffle will shuffle at the element level. nice.\n",
    "    shuffle_seed=1,\n",
    ")\n",
    "labels_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    str(DATASET_PATH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=1,\n",
    "    label_name=LABEL_COLUMN,\n",
    "    select_columns=[LABEL_COLUMN],\n",
    "    compression_type=\"GZIP\",\n",
    "    shuffle=True,\n",
    "    shuffle_seed=1,\n",
    ")\n",
    "validation_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    str(VALIDATION_DATASET_PATH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=1,\n",
    "    label_name=LABEL_COLUMN,\n",
    "    select_columns=INPUT_COLUMNS + [LABEL_COLUMN],\n",
    "    compression_type=\"GZIP\",\n",
    "    shuffle=True,\n",
    "    shuffle_seed=1,\n",
    ")\n",
    "\n",
    "def preprocess(batch, label):\n",
    "    features = tf.stack(\n",
    "        [tf.cast(tensor, tf.float32) \n",
    "         for feature_name, tensor in batch.items() \n",
    "         if feature_name in INPUT_COLUMNS\n",
    "        ], axis=1\n",
    "    )\n",
    "    return features, tf.stack(label)\n",
    "\n",
    "dataset = dataset.map(preprocess)\n",
    "validation_dataset = validation_dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06327dba-94c7-4a6d-9e13-e9fa9e440dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 10:56:40.034404: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-15 10:56:40.080440: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3492135000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class counts took: 161.37691235542297 seconds\n"
     ]
    }
   ],
   "source": [
    "# ===== Build Class Weights\n",
    "# def count(counts, batch):\n",
    "#     features, labels = batch\n",
    "#     for i in range(ACTION_SPACE_SIZE):\n",
    "#         class_i = labels == i\n",
    "#         class_i = tf.cast(class_i, tf.int32)\n",
    "#         counts[f\"class_{i}\"] += tf.reduce_sum(class_i)\n",
    "#     return counts\n",
    "\n",
    "# # This takes abount 3mins\n",
    "# start = time.time()\n",
    "# initial_state = {f\"class_{i}\": 0 for i in range(ACTION_SPACE_SIZE)}\n",
    "# counts = labels_dataset.reduce(initial_state=initial_state, reduce_func=count)  # { \"class_0\": tf.Tensor, ... }\n",
    "# print(\"Computing class counts took:\", time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36bc8647-544e-420c-89d3-c73248e4c735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.010215329,\n",
      " 1: 0.70093286,\n",
      " 2: 0.63069355,\n",
      " 3: 0.6780919,\n",
      " 4: 0.6585109,\n",
      " 5: 0.69551516,\n",
      " 6: 0.67753994,\n",
      " 7: 0.7052385,\n",
      " 8: 1.6360841,\n",
      " 9: 1.5638474,\n",
      " 10: 2.2866974,\n",
      " 11: 1.429554,\n",
      " 12: 2.3105004,\n",
      " 13: 1.6022286,\n",
      " 14: 2.488364,\n",
      " 15: 1.7313734,\n",
      " 16: 2.3713896,\n",
      " 17: 1.5406901,\n",
      " 18: 2.359625,\n",
      " 19: 2.099263,\n",
      " 20: 3329.4312,\n",
      " 21: 2.2093108,\n",
      " 22: 2.0313795,\n",
      " 23: 1.7919436,\n",
      " 24: 2.011741,\n",
      " 25: 1.8981934,\n",
      " 26: 2.1976445,\n",
      " 27: 1.8263474,\n",
      " 28: 2.1605654,\n",
      " 29: 1.9596416,\n",
      " 30: 2.1287923,\n",
      " 31: 1.8333871,\n",
      " 32: 1.8425187,\n",
      " 33: 1.2578131,\n",
      " 34: 1.2437173,\n",
      " 35: 1.2601935,\n",
      " 36: 1.8992763,\n",
      " 37: 1.2249563,\n",
      " 38: 1.6006881,\n",
      " 39: 1.1580629,\n",
      " 40: 1.105022,\n",
      " 41: 1.7569557,\n",
      " 42: 1.1785597,\n",
      " 43: 1.5786777,\n",
      " 44: 1.1810682,\n",
      " 45: 1.0664418,\n",
      " 46: 1.6772953,\n",
      " 47: 1.2597166,\n",
      " 48: 1.7709739,\n",
      " 49: 1.2071904,\n",
      " 50: 1.2423251,\n",
      " 51: 1.2493175,\n",
      " 52: 1.2050059,\n",
      " 53: 1.6123153,\n",
      " 54: 1.789055,\n",
      " 55: 1.1719223,\n",
      " 56: 1.2168974,\n",
      " 57: 1.596084,\n",
      " 58: 1.2186791,\n",
      " 59: 1.6312743,\n",
      " 60: 1.174817,\n",
      " 61: 1.6523232,\n",
      " 62: 1.5343001,\n",
      " 63: 6.672207,\n",
      " 64: 4.475042,\n",
      " 65: 12.516659,\n",
      " 66: 5.7403984,\n",
      " 67: 5.5306163,\n",
      " 68: 4.9841785,\n",
      " 69: 7.724898,\n",
      " 70: 13.479479,\n",
      " 71: 6.1315494,\n",
      " 72: 4.991651,\n",
      " 73: 5.5306163,\n",
      " 74: 6.142862,\n",
      " 75: 14.5390005,\n",
      " 76: 8.761662,\n",
      " 77: 5.1699243,\n",
      " 78: 4.769959,\n",
      " 79: 6.8226047,\n",
      " 80: 6.6588626,\n",
      " 81: 5.138011,\n",
      " 82: 11.764774,\n",
      " 83: 5.413709,\n",
      " 84: 8.1205635,\n",
      " 85: 13.989207,\n",
      " 86: 6.0206714,\n",
      " 87: 4.769959,\n",
      " 88: 4.5236835,\n",
      " 89: 7.498719,\n",
      " 90: 12.611482,\n",
      " 91: 7.3823304,\n",
      " 92: 4.3183284,\n",
      " 93: 2.3935523,\n",
      " 94: 2.4589593,\n",
      " 95: 2.4644196,\n",
      " 96: 2.4553328,\n",
      " 97: 2.4178874,\n",
      " 98: 2.4920893,\n",
      " 99: 2.3088982,\n",
      " 100: 1.8517414,\n",
      " 101: 1.8323783,\n",
      " 102: 2.351293,\n",
      " 103: 1.77286,\n",
      " 104: 1.7852178,\n",
      " 105: 2.2961595,\n",
      " 106: 1.756029,\n",
      " 107: 1.8075088,\n",
      " 108: 2.2882688,\n",
      " 109: 2.2618418,\n",
      " 110: 1.806528,\n",
      " 111: 1.8283532,\n",
      " 112: 1.725094,\n",
      " 113: 2.4337947,\n",
      " 114: 1.9323454,\n",
      " 115: 1.7277796,\n",
      " 116: 1.86314,\n",
      " 117: 5.8720126,\n",
      " 118: 70.83896,\n",
      " 119: 55.49052,\n",
      " 120: 5.3787255,\n",
      " 121: 40.11363,\n",
      " 122: 5.3787255,\n",
      " 123: 66.58862,\n",
      " 124: 57.403984,\n",
      " 125: 4.947149,\n",
      " 126: 50.445927,\n",
      " 127: 5.243199,\n",
      " 128: 56.431038,\n",
      " 129: 89.98463,\n",
      " 130: 5.2349544,\n",
      " 131: 46.893394,\n",
      " 132: 5.029352,\n",
      " 133: 5.539819,\n",
      " 134: 54.580837,\n",
      " 135: 75.66889,\n",
      " 136: 4.991651,\n",
      " 137: 49.693,\n",
      " 138: 46.2421,\n",
      " 139: 5.259765,\n",
      " 140: 87.61661,\n",
      " 141: 38.714317,\n",
      " 142: 5.0066633,\n",
      " 143: 61.65613,\n",
      " 144: 64.02753,\n",
      " 145: 4.5175457,\n",
      " 146: 48.252625,\n",
      " 147: 4.715908,\n",
      " 148: 4.643558,\n",
      " 149: 4.9545107,\n",
      " 150: 4.749545,\n",
      " 151: 4.669609,\n",
      " 152: 4.709238,\n",
      " 153: 4.284982,\n",
      " 154: 3.306287,\n",
      " 155: 3.3495283,\n",
      " 156: 4.6177964,\n",
      " 157: 3.3664622,\n",
      " 158: 3.306287,\n",
      " 159: 4.3239365,\n",
      " 160: 3.1708868,\n",
      " 161: 3.2932057,\n",
      " 162: 4.542198,\n",
      " 163: 4.2575846,\n",
      " 164: 3.2641485,\n",
      " 165: 3.5269399,\n",
      " 166: 3.155859,\n",
      " 167: 4.776802,\n",
      " 168: 3.6189468,\n",
      " 169: 3.2513976,\n",
      " 170: 3.4537668,\n",
      " 171: 36.99368,\n",
      " 172: 1664.7156,\n",
      " 173: 1664.7156,\n",
      " 174: 33.29431,\n",
      " 175: 1664.7156,\n",
      " 176: 34.681576,\n",
      " 177: 554.9052,\n",
      " 178: 1664.7156,\n",
      " 179: 35.41948,\n",
      " 180: 832.3578,\n",
      " 181: 29.727066,\n",
      " 182: 665.8862,\n",
      " 183: 1109.8104,\n",
      " 184: 34.681576,\n",
      " 185: 1109.8104,\n",
      " 186: 29.727066,\n",
      " 187: 41.61789,\n",
      " 188: 665.8862,\n",
      " 189: 3329.4312,\n",
      " 190: 31.116179,\n",
      " 191: 1109.8104,\n",
      " 192: 665.8862,\n",
      " 193: 34.32403,\n",
      " 194: 3329.4312,\n",
      " 195: 554.9052,\n",
      " 196: 36.58716,\n",
      " 197: 1109.8104,\n",
      " 198: 1109.8104,\n",
      " 199: 31.70887,\n",
      " 200: 475.63306,\n",
      " 201: 1.1556512,\n",
      " 202: 2.2151904,\n",
      " 203: 114.80797,\n",
      " 204: 41.104088,\n",
      " 205: 3329.4312,\n",
      " 206: 3329.4312,\n",
      " 207: 1109.8104,\n",
      " 208: 104.04472,\n",
      " 209: 3329.4312,\n",
      " 210: 1664.7156,\n",
      " 211: 1109.8104,\n",
      " 212: 3329.4312,\n",
      " 213: 3329.4312,\n",
      " 214: 3329.4312,\n",
      " 215: 3329.4312,\n",
      " 216: 3329.4312,\n",
      " 217: 47.5633,\n",
      " 218: 3329.4312,\n",
      " 219: 3329.4312,\n",
      " 220: 3329.4312,\n",
      " 221: 3329.4312,\n",
      " 222: 3329.4312,\n",
      " 223: 16.73081,\n",
      " 224: 67.94757,\n",
      " 225: 57.403984,\n",
      " 226: 175.23322,\n",
      " 227: 158.54434,\n",
      " 228: 35.41948,\n",
      " 229: 0.61292917,\n",
      " 230: 12.42325,\n",
      " 231: 1.178977,\n",
      " 232: 2.1287923,\n",
      " 233: 1.070901,\n",
      " 234: 17.523323,\n",
      " 235: 1.7376989,\n",
      " 236: 3.2199528,\n",
      " 237: 0.4808537,\n",
      " 238: 0.31221223,\n",
      " 239: 0.91694605,\n",
      " 240: 1.5854434,\n",
      " 241: 0.45696282,\n",
      " 242: 0.42548642,\n",
      " 243: 12.107022,\n",
      " 244: 5.1699243,\n",
      " 245: 0.7755488,\n",
      " 246: 0.64674264,\n",
      " 247: 10.119852,\n",
      " 248: 2.271099,\n",
      " 249: 5.3100977,\n",
      " 250: 38.269325,\n",
      " 251: 9.850389,\n",
      " 252: 13.159807,\n",
      " 253: 7.549731,\n",
      " 254: 67.94757,\n",
      " 255: 12.516659,\n",
      " 256: 16.564333,\n",
      " 257: 4.1410832,\n",
      " 258: 3.1321082,\n",
      " 259: 7.0688562,\n",
      " 260: 9.968357,\n",
      " 261: 4.592319,\n",
      " 262: 3.4466162,\n",
      " 263: 55.49052,\n",
      " 264: 21.07235,\n",
      " 265: 9.022849,\n",
      " 266: 7.760912,\n",
      " 267: 69.36315,\n",
      " 268: 16.162287,\n",
      " 269: 11.480797,\n",
      " 270: 100.89185,\n",
      " 271: 15.485726,\n",
      " 272: 20.425957,\n",
      " 273: 18.193613,\n",
      " 274: 123.31226,\n",
      " 275: 27.978415,\n",
      " 276: 32.964664,\n",
      " 277: 7.7070165,\n",
      " 278: 7.024116,\n",
      " 279: 13.757979,\n",
      " 280: 16.986893,\n",
      " 281: 9.14679,\n",
      " 282: 7.6188354,\n",
      " 283: 50.445927,\n",
      " 284: 33.973785,\n",
      " 285: 12.954985,\n",
      " 286: 12.707752,\n",
      " 287: 138.7263,\n",
      " 288: 41.104088,\n",
      " 289: 0.010377976}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_215136/1738080328.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights = (1 / counts_array) * (counts_array.sum() / ACTION_SPACE_SIZE)\n"
     ]
    }
   ],
   "source": [
    "# counts_array = np.array([counts[f\"class_{i}\"].numpy() for i in range(ACTION_SPACE_SIZE)]).astype(np.float32)\n",
    "\n",
    "# fractions = counts_array/counts_array.sum()\n",
    "# weights = (1 / counts_array) * (counts_array.sum() / ACTION_SPACE_SIZE)\n",
    "# weights[weights == np.inf] = -np.inf  # Drop inf to min value (to sort of \"clip\" importance)\n",
    "# weights[weights == -np.inf] = np.max(weights)  # Drop inf to min value (to sort of \"clip\" importance)\n",
    "# class_weight = {i: weights[i] for i in range(ACTION_SPACE_SIZE)}\n",
    "# pprint(class_weight)\n",
    "\n",
    "# {0: 0.010215329, then many in 0.5-2 range, 289: 0.010377976}\n",
    "\n",
    "# === Rejection Resampling\n",
    "# def class_func(features, label):\n",
    "#     return label\n",
    "# n = ACTION_SPACE_SIZE\n",
    "# target_dist = [1.0 / n for i in range(n)]\n",
    "# resampler = tf.data.experimental.rejection_resample(\n",
    "#     class_func, target_dist=target_dist)\n",
    "\n",
    "# dataset = dataset.unbatch().apply(resampler).batch(BATCH_SIZE)\\\n",
    "#     .map(lambda extra_label, features_and_label: features_and_label)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f32d525-105f-4203-a5c9-4a279e20f6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 614)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                9840      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 290)               4930      \n",
      "=================================================================\n",
      "Total params: 14,770\n",
      "Trainable params: 14,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Things to try: Dropout. Less Learning Rate. Simpler Models. Validation Graph.\n",
    "LAYERS = [16]\n",
    "\n",
    "inputs = tf.keras.Input(shape=INPUT_SHAPE)\n",
    "\n",
    "last_layer = inputs\n",
    "for num_neurons in LAYERS:\n",
    "    last_layer = tf.keras.layers.Dense(num_neurons, activation=\"relu\", dtype='float64')(last_layer)\n",
    "\n",
    "last_layer = tf.keras.layers.Dropout(0.2)(last_layer)\n",
    "output_dense = tf.keras.layers.Dense(ACTION_SPACE_SIZE, dtype='float64')(last_layer)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output_dense)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04b1b8-2a59-40cc-93e0-43818d152010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bcollazo/BryanCode/catanatron/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/10\n",
      "7544/7544 [==============================] - 914s 121ms/step - loss: 1.6939 - categorical_accuracy: 0.0111 - val_loss: 4.5561 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5036/7544 [===================>..........] - ETA: 5:15 - loss: 1.6010 - categorical_accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# Shuffle at the individual element level\n",
    "# SHUFFLE_BUFFER_SIZE = 20000  # each game is like 200 samples...\n",
    "# dataset = dataset.unbatch().shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "# validation_dataset = validation_dataset.unbatch().shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "class_weight = {i: 1 for i in range(290)}\n",
    "class_weight[0] = 0.01\n",
    "class_weight[289] = 0.01\n",
    "\n",
    "history = model.fit(\n",
    "    dataset, \n",
    "    epochs=10,\n",
    "    # steps_per_epoch=10,\n",
    "    # validation_steps=10,\n",
    "    validation_data=validation_dataset,\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff3779-c8e2-4ade-ba41-ca16350a397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for categorical_accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model categorical_accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72935405-bb52-4bb0-a7d0-4e87b770f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2b36b-d65f-4ec9-8b24-c2a59a76945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/models/ab2-copycat-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fc396-f179-4544-9fe8-107051756824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from catanatron.game import Game\n",
    "from catanatron.models.player import Player, RandomPlayer, Color\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "from catanatron_experimental.play import play_batch\n",
    "from catanatron_gym.envs.catanatron_env import to_action_space, ACTION_SPACE_SIZE, from_action_space\n",
    "from catanatron_gym.features import create_sample_vector, create_sample\n",
    "\n",
    "\n",
    "class MyPlayer(Player):\n",
    "    def decide(self, game, playable_actions):\n",
    "        \"\"\"Should return one of the playable_actions.\n",
    "\n",
    "        Args:\n",
    "            game (Game): complete game state. read-only.\n",
    "            playable_actions (Iterable[Action]): options to choose from\n",
    "        Return:\n",
    "            action (Action): Chosen element of playable_actions\n",
    "        \"\"\"\n",
    "        # ===== YOUR CODE HERE =====\n",
    "        action_ints = [to_action_space(a) for a in playable_actions]\n",
    "        mask = np.zeros(ACTION_SPACE_SIZE, dtype=np.float)\n",
    "        mask[action_ints] = 1\n",
    "        mask[mask == 0] = np.nan\n",
    "\n",
    "        # Get action probabilities with neural network.\n",
    "        vector = create_sample_vector(game, self.color)\n",
    "        record = create_sample(game, self.color)\n",
    "        keys = [name[2:] for name in INPUT_COLUMNS] # remove the F_ prefix\n",
    "        vector = [record[x] for x in keys]\n",
    "        X = [vector]\n",
    "        result = model.call(tf.convert_to_tensor(X))\n",
    "\n",
    "        # Multiply mask with output, and take max.\n",
    "        clipped_probabilities = np.multiply(mask, result[0])\n",
    "        clipped_probabilities[np.isnan(clipped_probabilities)] = -np.inf\n",
    "        action_index = np.argmax(clipped_probabilities)\n",
    "        action = from_action_space(action_index, playable_actions)\n",
    "        \n",
    "        # print(result)\n",
    "        # print(\"Playing\", action)\n",
    "        \n",
    "        return action\n",
    "        # ===== END YOUR CODE =====\n",
    "\n",
    "# Play a simple 4v4 game. Edit MyPlayer with your logic!\n",
    "players = [\n",
    "    MyPlayer(Color.RED),\n",
    "    RandomPlayer(Color.WHITE),\n",
    "]\n",
    "wins, results_by_player, games = play_batch(5, players)\n",
    "\n",
    "pprint(wins)\n",
    "pprint(results_by_player)\n",
    "\n",
    "# Results: [64, 32, 32] with LR 1e-4 made a bot that won 60% of games against Random. Had %60 categorical accuracy."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f78080196a7cdfc318a049c523009e8b30d77bd6b3e4da46ec3860e07bf4591"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
