{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df9b28-2540-44f9-a795-cf0d17fa2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "# try to suppress TF output before any potentially tf-importing modules\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe89ef1-7b1e-49dc-beed-3f72abd20197",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../../../data/fixed-map-rands/main.csv.gzip\"\n",
    "# VALIDATION_DATASET_PATH = \"../../../data/fixed-map-vps-1v1/main.csv.gzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83274991-c4e1-4f4b-b7b1-e9c56a369972",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATASET_PATH, nrows=10, compression='gzip')\n",
    "# validation_data = pd.read_csv(VALIDATION_DATASET_PATH, nrows=10, compression='gzip')\n",
    "\n",
    "# assert (data.columns == validation_data.columns).all()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbda04-9a1b-4a7b-8aa2-cf725b0ca91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Read Dataset\n",
    "INPUT_COLUMNS = list(filter(lambda x: x.startswith(\"F_\") and not x.startswith(\"F_PORT\") and not x.startswith(\"F_TILE\"), data.columns))\n",
    "# pprint(INPUT_COLUMNS)\n",
    "NUM_FEATURES = len(INPUT_COLUMNS)\n",
    "LABEL_COLUMN = \"RETURN\"\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "NORMALIZATION = False\n",
    "NORMALIZATION_DIRECTORY = \"data/reachability\"\n",
    "NORMALIZATION_MEAN_PATH = Path(NORMALIZATION_DIRECTORY, \"samples-mean.npy\")\n",
    "NORMALIZATION_VARIANCE_PATH = Path(NORMALIZATION_DIRECTORY, \"samples-variance.npy\")\n",
    "\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    str(DATASET_PATH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=1,\n",
    "    label_name=LABEL_COLUMN,\n",
    "    select_columns=INPUT_COLUMNS + [LABEL_COLUMN],\n",
    "    compression_type=\"GZIP\",\n",
    "    shuffle=True,  # shuffle will shuffle at the element level. nice.\n",
    "    shuffle_seed=1,\n",
    "    shuffle_buffer_size=1000,\n",
    "    prefetch_buffer_size=100,\n",
    ")\n",
    "# validation_dataset = tf.data.experimental.make_csv_dataset(\n",
    "#     str(VALIDATION_DATASET_PATH),\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     num_epochs=1,\n",
    "#     label_name=LABEL_COLUMN,\n",
    "#     select_columns=INPUT_COLUMNS + [LABEL_COLUMN],\n",
    "#     compression_type=\"GZIP\",\n",
    "#     shuffle=True,\n",
    "#     shuffle_seed=1,\n",
    "#     shuffle_buffer_size=1000,\n",
    "#     prefetch_buffer_size=100,\n",
    "# )\n",
    "\n",
    "def preprocess(batch, label):\n",
    "    features = tf.stack(\n",
    "        [tf.cast(tensor, tf.float32) \n",
    "         for feature_name, tensor in batch.items() \n",
    "         if feature_name in INPUT_COLUMNS\n",
    "        ], axis=1\n",
    "    )\n",
    "    return features, tf.stack(label)\n",
    "\n",
    "dataset = dataset.map(preprocess)\n",
    "# validation_dataset = validation_dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83885e2-bcbb-4877-8e38-14c1df467497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Configuration\n",
    "EPOCHS = 100\n",
    "PREFETCH_BUFFER_SIZE = 10\n",
    "\n",
    "MODEL_NAME = \"1v1-value-network\"\n",
    "MODEL_PATH = f\"data/models/{MODEL_NAME}\"\n",
    "LOG_DIR = f\"data/logs/{MODEL_NAME}/{int(time.time())}\"\n",
    "\n",
    "# ===== REGULAR MODEL\n",
    "init = tf.keras.initializers.HeUniform()\n",
    "inputs = tf.keras.Input(shape=(NUM_FEATURES,))\n",
    "outputs = inputs\n",
    "\n",
    "if NORMALIZATION:\n",
    "    mean = np.load(NORMALIZATION_MEAN_PATH)[FEATURE_INDICES]\n",
    "    variance = np.load(NORMALIZATION_VARIANCE_PATH)[FEATURE_INDICES]\n",
    "    normalizer_layer = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "        mean=mean, variance=variance\n",
    "    )\n",
    "    outputs = normalizer_layer(outputs)\n",
    "\n",
    "# outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
    "# outputs = tf.keras.layers.Dense(352, activation=\"relu\")(outputs)\n",
    "# outputs = tf.keras.layers.Dense(320, activation=\"relu\")(outputs)\n",
    "# outputs = tf.keras.layers.Dense(160, activation=\"relu\")(outputs)\n",
    "# outputs = tf.keras.layers.Dense(512, activation=\"relu\")(outputs)\n",
    "# outputs = tf.keras.layers.Dense(352, activation=\"relu\")(outputs)\n",
    "# outputs = tf.keras.layers.Dense(64, activation=\"relu\")(outputs)\n",
    "# outputs = tf.keras.layers.Dense(32, activation=\"relu\")(outputs)\n",
    "outputs = tf.keras.layers.Dense(\n",
    "    8, activation=\"relu\", kernel_initializer=\"random_normal\"\n",
    ")(outputs)\n",
    "\n",
    "# BINARY CLASSIFICATION SETUP\n",
    "outputs = tf.keras.layers.Dense(\n",
    "    units=1,\n",
    "    activation=\"sigmoid\",\n",
    "    kernel_initializer=\"random_normal\",\n",
    "    kernel_regularizer=\"l2\",\n",
    ")(outputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    metrics=[\"mae\", \"accuracy\"],\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, clipnorm=1),\n",
    "    loss=\"binary_crossentropy\",\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93efb95-7a57-4a9d-bfd3-6128a93e8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Fit Final Model\n",
    "start = time.time()\n",
    "history = model.fit(\n",
    "    dataset, \n",
    "    epochs=50,\n",
    "    # steps_per_epoch=10,\n",
    "    # validation_steps=10,\n",
    "    # validation_data=validation_dataset,\n",
    "    # class_weight=class_weight,\n",
    "    callbacks=[\n",
    "        # tf.keras.callbacks.EarlyStopping(\n",
    "        #     monitor=\"val_mae\", patience=1, min_delta=0.0001\n",
    "        # ),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=LOG_DIR, histogram_freq=1, write_graph=True\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "print(\"Training took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15b8c9-a571-447b-a3b4-68dafd85b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for categorical_accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca41a9-4c44-4d0c-b8e7-cb7a2302d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f24ed0-2b0d-46de-a7dd-4f6b9b5c56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Saved model at:\", MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
